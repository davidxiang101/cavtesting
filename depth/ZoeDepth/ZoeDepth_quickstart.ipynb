{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHpqqdvza03n"
      },
      "source": [
        "## Welcome to ZoeDepth Colab notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnfC4dBNbTMh"
      },
      "source": [
        "This notebook provides an easy to use interface for the depth estimation model \"ZoeDepth\".\n",
        "\n",
        "It accompanies our paper : [ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth](https://arxiv.org/abs/2302.12288v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF0_pagYc1NR"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX21oVM6SvSq",
        "outputId": "580cb3bb-e1c5-4fa5-f3cd-587d3b2c4566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.8/dist-packages (0.6.12)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from timm) (0.12.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mwb90-BTC9w",
        "outputId": "030b9b43-3c04-42d2-ad65-485a717e8a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ZoeDepth' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/isl-org/ZoeDepth.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFLgRBC3TVL2",
        "outputId": "ad805cce-67e9-4d7e-d5ca-0a3742bc41f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ZoeDepth\n"
          ]
        }
      ],
      "source": [
        "cd ZoeDepth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MEhLSXKcAzE"
      },
      "source": [
        "Sanity checks, to make sure everything is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c7C22G1Tncc",
        "outputId": "4ad4775f-b784-4d7e-acdb-bfeaeebdc235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /Users/cactuscolada/.cache/torch/hub/master.zip\n",
            "WARNING: Running on CPU. This will be slow. Check your CUDA installation.\n",
            "******************** Testing zoedepth ********************\n",
            "Config:\n",
            "{'attractor_alpha': 1000,\n",
            " 'attractor_gamma': 2,\n",
            " 'attractor_kind': 'mean',\n",
            " 'attractor_type': 'inv',\n",
            " 'aug': True,\n",
            " 'bin_centers_type': 'softplus',\n",
            " 'bin_embedding_dim': 128,\n",
            " 'clip_grad': 0.1,\n",
            " 'dataset': 'nyu',\n",
            " 'distributed': True,\n",
            " 'force_keep_ar': True,\n",
            " 'gpu': None,\n",
            " 'img_size': [384, 512],\n",
            " 'inverse_midas': False,\n",
            " 'log_images_every': 0.1,\n",
            " 'max_temp': 50.0,\n",
            " 'max_translation': 100,\n",
            " 'memory_efficient': True,\n",
            " 'midas_model_type': 'DPT_BEiT_L_384',\n",
            " 'min_temp': 0.0212,\n",
            " 'model': 'zoedepth',\n",
            " 'n_attractors': [16, 8, 4, 1],\n",
            " 'n_bins': 64,\n",
            " 'name': 'ZoeDepth',\n",
            " 'notes': '',\n",
            " 'output_distribution': 'logbinomial',\n",
            " 'prefetch': False,\n",
            " 'pretrained_resource': 'url::https://github.com/isl-org/ZoeDepth/releases/download/v1.0/ZoeD_M12_N.pt',\n",
            " 'print_losses': False,\n",
            " 'project': 'ZoeDepth',\n",
            " 'random_crop': False,\n",
            " 'random_translate': False,\n",
            " 'root': '.',\n",
            " 'save_dir': '/Users/cactuscolada/shortcuts/monodepth3_checkpoints',\n",
            " 'shared_dict': None,\n",
            " 'tags': '',\n",
            " 'train_midas': False,\n",
            " 'translate_prob': 0.2,\n",
            " 'uid': None,\n",
            " 'use_amp': False,\n",
            " 'use_pretrained_midas': False,\n",
            " 'use_shared_dict': False,\n",
            " 'validate_every': 0.25,\n",
            " 'version_name': 'v1',\n",
            " 'workers': 16}\n",
            "img_size [384, 512]\n",
            "Using cache found in /Users/cactuscolada/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1702400154748/work/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Params passed to Resize transform:\n",
            "\twidth:  512\n",
            "\theight:  384\n",
            "\tresize_target:  True\n",
            "\tkeep_aspect_ratio:  True\n",
            "\tensure_multiple_of:  32\n",
            "\tresize_method:  minimal\n",
            "Using pretrained resource url::https://github.com/isl-org/ZoeDepth/releases/download/v1.0/ZoeD_M12_N.pt\n",
            "Loaded successfully\n",
            "--------------------Testing on a random input--------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"sanity.py\", line 56, in <module>\n",
            "    out = model(x)\n",
            "  File \"/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/Users/cactuscolada/Projects/cavtesting/depth/ZoeDepth/zoedepth/models/zoedepth/zoedepth_v1.py\", line 144, in forward\n",
            "    rel_depth, out = self.core(x, denorm=denorm, return_rel_depth=True)\n",
            "  File \"/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/Users/cactuscolada/Projects/cavtesting/depth/ZoeDepth/zoedepth/models/base_models/midas.py\", line 262, in forward\n",
            "    x = self.prep(x)\n",
            "  File \"/Users/cactuscolada/Projects/cavtesting/depth/ZoeDepth/zoedepth/models/base_models/midas.py\", line 186, in __call__\n",
            "    return self.normalization(self.resizer(x))\n",
            "  File \"/Users/cactuscolada/Projects/cavtesting/depth/ZoeDepth/zoedepth/models/base_models/midas.py\", line 173, in __call__\n",
            "    return nn.functional.interpolate(x, (height, width), mode='bilinear', align_corners=True)\n",
            "  File \"/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/functional.py\", line 3924, in interpolate\n",
            "    raise TypeError(\n",
            "TypeError: expected size to be one of int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], but got size with types [<class 'numpy.int64'>, <class 'numpy.int64'>]\n"
          ]
        }
      ],
      "source": [
        "!python sanity.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JVv53wUATtdi",
        "outputId": "1542ef79-5f46-4f17-c973-0e56194c53b8"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download file, only works on Chrome\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      3\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Download file, only works on Chrome\n",
        "from google.colab import files\n",
        "files.download(\"pred.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqWnTZHqcaRR"
      },
      "source": [
        "# Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHxbIe1-VXVp",
        "outputId": "ee333166-5718-4572-e30c-99ee9897f148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img_size [384, 512]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /Users/cactuscolada/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params passed to Resize transform:\n",
            "\twidth:  512\n",
            "\theight:  384\n",
            "\tresize_target:  True\n",
            "\tkeep_aspect_ratio:  True\n",
            "\tensure_multiple_of:  32\n",
            "\tresize_method:  minimal\n",
            "Using pretrained resource url::https://github.com/isl-org/ZoeDepth/releases/download/v1.0/ZoeD_M12_N.pt\n",
            "Loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from zoedepth.utils.misc import get_image_from_url, colorize\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "zoe = torch.hub.load(\".\", \"ZoeD_N\", source=\"local\", pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4roIdsrSW6wK"
      },
      "outputs": [],
      "source": [
        "zoe = zoe.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsJ1dyJtcpDM"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "OJ9bY7rrVuAq",
        "outputId": "b33a6b54-fdbb-4515-b0fd-ff3ede3ad9b9"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "expected size to be one of int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], but got size with types [<class 'numpy.int64'>, <class 'numpy.int64'>]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m img_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://static1.squarespace.com/static/6213c340453c3f502425776e/62f2452bc121595f4d87c713/62f3c63c5eec2b12a333f851/1661442296756/Screenshot+2022-08-10+at+15.55.27.png?format=1500w\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#@param {type:\"string\"}\u001b[39;00m\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../output_image.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m depth \u001b[38;5;241m=\u001b[39m \u001b[43mzoe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m colored_depth \u001b[38;5;241m=\u001b[39m colorize(depth)\n\u001b[1;32m      7\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m7\u001b[39m))\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/depth_model.py:141\u001b[0m, in \u001b[0;36mDepthModel.infer_pil\u001b[0;34m(self, pil_img, pad_input, with_flip_aug, output_type, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mInference interface for the model for PIL image\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    output_type (str, optional): output type. Supported values are 'numpy', 'pil' and 'tensor'. Defaults to \"numpy\".\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m x \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToTensor()(pil_img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 141\u001b[0m out_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_flip_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_flip_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out_tensor\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/depth_model.py:126\u001b[0m, in \u001b[0;36mDepthModel.infer\u001b[0;34m(self, x, pad_input, with_flip_aug, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03mInference interface for the model\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    torch.Tensor: output tensor of shape (b, 1, h, w)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_flip_aug:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_with_flip_aug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_with_pad_aug(x, pad_input\u001b[38;5;241m=\u001b[39mpad_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/depth_model.py:110\u001b[0m, in \u001b[0;36mDepthModel.infer_with_flip_aug\u001b[0;34m(self, x, pad_input, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03mInference interface for the model with horizontal flip augmentation\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mHorizontal flip augmentation improves the accuracy of the model by averaging the output of the model with and without horizontal flip.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    torch.Tensor: output tensor of shape (b, 1, h, w)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# infer with horizontal flip and average\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_with_pad_aug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m out_flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_with_pad_aug(torch\u001b[38;5;241m.\u001b[39mflip(x, dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m3\u001b[39m]), pad_input\u001b[38;5;241m=\u001b[39mpad_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    112\u001b[0m out \u001b[38;5;241m=\u001b[39m (out \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mflip(out_flip, dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m3\u001b[39m])) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/depth_model.py:88\u001b[0m, in \u001b[0;36mDepthModel._infer_with_pad_aug\u001b[0;34m(self, x, pad_input, fh, fw, upsampling_mode, padding_mode, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         padding \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [pad_h, pad_h]\n\u001b[1;32m     87\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, padding, mode\u001b[38;5;241m=\u001b[39mpadding_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 88\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]:\n\u001b[1;32m     90\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(out, size\u001b[38;5;241m=\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]), mode\u001b[38;5;241m=\u001b[39mupsampling_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/depth_model.py:55\u001b[0m, in \u001b[0;36mDepthModel._infer\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_infer\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Inference interface for the model\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        torch.Tensor: output tensor of shape (b, 1, h, w)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/zoedepth/zoedepth_v1.py:144\u001b[0m, in \u001b[0;36mZoeDepth.forward\u001b[0;34m(self, x, return_final_centers, denorm, return_probs, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_input_width \u001b[38;5;241m=\u001b[39m w\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_input_height \u001b[38;5;241m=\u001b[39m h\n\u001b[0;32m--> 144\u001b[0m rel_depth, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_rel_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# print(\"output shapes\", rel_depth.shape, out.shape)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m outconv_activation \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/base_models/midas.py:262\u001b[0m, in \u001b[0;36mMidasCore.forward\u001b[0;34m(self, x, denorm, return_rel_depth)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m denorm:\n\u001b[1;32m    261\u001b[0m         x \u001b[38;5;241m=\u001b[39m denormalize(x)\n\u001b[0;32m--> 262\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# print(\"Shape after prep: \", x.shape)\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable):\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# print(\"Input size to Midascore\", x.shape)\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/base_models/midas.py:186\u001b[0m, in \u001b[0;36mPrepForMidas.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/Projects/cavtesting/depth/ZoeDepth/./zoedepth/models/base_models/midas.py:173\u001b[0m, in \u001b[0;36mResize.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    172\u001b[0m     width, height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_size(\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/envs/patchfusion/lib/python3.8/site-packages/torch/nn/functional.py:3924\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m   3923\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_integer(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m size):\n\u001b[0;32m-> 3924\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected size to be one of int or Tuple[int] or Tuple[int, int] or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3926\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple[int, int, int], but got size with types \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mx\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39msize]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3927\u001b[0m             )\n\u001b[1;32m   3928\u001b[0m     output_size \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m   3929\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mTypeError\u001b[0m: expected size to be one of int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], but got size with types [<class 'numpy.int64'>, <class 'numpy.int64'>]"
          ]
        }
      ],
      "source": [
        "#@title Predicting depth from a url image\n",
        "img_url = \"http://static1.squarespace.com/static/6213c340453c3f502425776e/62f2452bc121595f4d87c713/62f3c63c5eec2b12a333f851/1661442296756/Screenshot+2022-08-10+at+15.55.27.png?format=1500w\" #@param {type:\"string\"}\n",
        "img = Image.open(\"../output_image.jpeg\")\n",
        "depth = zoe.infer_pil(img)\n",
        "\n",
        "colored_depth = colorize(depth)\n",
        "fig, axs = plt.subplots(1,2, figsize=(15,7))\n",
        "for ax, im, title in zip(axs, [img, colored_depth], ['Input', 'Predicted Depth']):\n",
        "  ax.imshow(im)\n",
        "  ax.axis('off')\n",
        "  ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yGmrrFowXYNM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OF0_pagYc1NR",
        "wqWnTZHqcaRR"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
